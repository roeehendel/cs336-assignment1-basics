{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class GeneralConfig:\n",
    "    context_length: int\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TransformerLMConfig:\n",
    "    vocab_size: int\n",
    "    num_layers: int\n",
    "    d_model: int\n",
    "    num_heads: int\n",
    "    d_ff: int = None\n",
    "\n",
    "    # TODO: move context_length to a separate config\n",
    "    context_length: int\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.d_ff = self.d_ff or 4 * self.d_model\n",
    "\n",
    "\n",
    "general_config = {\n",
    "    \"vocab_size\": 50_257,\n",
    "    \"context_length\": 1_024,\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt-2-small\": TransformerLMConfig(\n",
    "        num_layers=12,\n",
    "        d_model=768,\n",
    "        num_heads=12,\n",
    "    ),\n",
    "    \"gpt-2-medium\": TransformerLMConfig(\n",
    "        num_layers=24,\n",
    "        d_model=1_024,\n",
    "        num_heads=16,\n",
    "    ),\n",
    "    \"gpt-2-large\": TransformerLMConfig(\n",
    "        num_layers=36,\n",
    "        d_model=1_280,\n",
    "        num_heads=20,\n",
    "    ),\n",
    "    \"gpt-2-xl\": TransformerLMConfig(\n",
    "        num_layers=48,\n",
    "        d_model=1_600,\n",
    "        num_heads=25,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "non-default argument 'context_length' follows default argument 'd_ff'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdataclasses\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dataclass\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;129;43m@dataclass\u001b[39;49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43;01mTransformerLMConfig\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.3_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/dataclasses.py:1305\u001b[39m, in \u001b[36mdataclass\u001b[39m\u001b[34m(cls, init, repr, eq, order, unsafe_hash, frozen, match_args, kw_only, slots, weakref_slot)\u001b[39m\n\u001b[32m   1302\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m wrap\n\u001b[32m   1304\u001b[39m \u001b[38;5;66;03m# We're called as @dataclass without parens.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1305\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.3_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/dataclasses.py:1295\u001b[39m, in \u001b[36mdataclass.<locals>.wrap\u001b[39m\u001b[34m(cls)\u001b[39m\n\u001b[32m   1294\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrap\u001b[39m(\u001b[38;5;28mcls\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1295\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_process_class\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mrepr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munsafe_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1296\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mfrozen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatch_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkw_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslots\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1297\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mweakref_slot\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.3_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/dataclasses.py:1078\u001b[39m, in \u001b[36m_process_class\u001b[39m\u001b[34m(cls, init, repr, eq, order, unsafe_hash, frozen, match_args, kw_only, slots, weakref_slot)\u001b[39m\n\u001b[32m   1074\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m init:\n\u001b[32m   1075\u001b[39m     \u001b[38;5;66;03m# Does this class have a post-init function?\u001b[39;00m\n\u001b[32m   1076\u001b[39m     has_post_init = \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, _POST_INIT_NAME)\n\u001b[32m-> \u001b[39m\u001b[32m1078\u001b[39m     \u001b[43m_init_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_init_fields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1079\u001b[39m \u001b[43m             \u001b[49m\u001b[43mstd_init_fields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1080\u001b[39m \u001b[43m             \u001b[49m\u001b[43mkw_only_init_fields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1081\u001b[39m \u001b[43m             \u001b[49m\u001b[43mfrozen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1082\u001b[39m \u001b[43m             \u001b[49m\u001b[43mhas_post_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1083\u001b[39m \u001b[43m             \u001b[49m\u001b[38;5;66;43;03m# The name to use for the \"self\"\u001b[39;49;00m\n\u001b[32m   1084\u001b[39m \u001b[43m             \u001b[49m\u001b[38;5;66;43;03m# param in __init__.  Use \"self\"\u001b[39;49;00m\n\u001b[32m   1085\u001b[39m \u001b[43m             \u001b[49m\u001b[38;5;66;43;03m# if possible.\u001b[39;49;00m\n\u001b[32m   1086\u001b[39m \u001b[43m             \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m__dataclass_self__\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mself\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\n\u001b[32m   1087\u001b[39m \u001b[43m             \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mself\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1088\u001b[39m \u001b[43m             \u001b[49m\u001b[43mfunc_builder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1089\u001b[39m \u001b[43m             \u001b[49m\u001b[43mslots\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1090\u001b[39m \u001b[43m             \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1092\u001b[39m _set_new_attribute(\u001b[38;5;28mcls\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m__replace__\u001b[39m\u001b[33m'\u001b[39m, _replace)\n\u001b[32m   1094\u001b[39m \u001b[38;5;66;03m# Get the fields as a list, and include only real fields.  This is\u001b[39;00m\n\u001b[32m   1095\u001b[39m \u001b[38;5;66;03m# used in all of the following methods.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.3_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/dataclasses.py:627\u001b[39m, in \u001b[36m_init_fn\u001b[39m\u001b[34m(fields, std_fields, kw_only_fields, frozen, has_post_init, self_name, func_builder, slots)\u001b[39m\n\u001b[32m    625\u001b[39m             seen_default = f\n\u001b[32m    626\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m seen_default:\n\u001b[32m--> \u001b[39m\u001b[32m627\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mnon-default argument \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf.name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    628\u001b[39m                             \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mfollows default argument \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseen_default.name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m    630\u001b[39m \u001b[38;5;28mlocals\u001b[39m = {**{\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m__dataclass_type_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m__\u001b[39m\u001b[33m'\u001b[39m: f.type \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fields},\n\u001b[32m    631\u001b[39m           **{\u001b[33m'\u001b[39m\u001b[33m__dataclass_HAS_DEFAULT_FACTORY__\u001b[39m\u001b[33m'\u001b[39m: _HAS_DEFAULT_FACTORY,\n\u001b[32m    632\u001b[39m              \u001b[33m'\u001b[39m\u001b[33m__dataclass_builtins_object__\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mobject\u001b[39m,\n\u001b[32m    633\u001b[39m              }\n\u001b[32m    634\u001b[39m           }\n\u001b[32m    636\u001b[39m body_lines = []\n",
      "\u001b[31mTypeError\u001b[39m: non-default argument 'context_length' follows default argument 'd_ff'"
     ]
    }
   ],
   "source": [
    "def count_transformer_lm_params(cfg: TransformerLMConfig):\n",
    "    token_embeddings = cfg.vocab_size * cfg.d_model\n",
    "    glu = 3 * cfg.d_model * cfg.d_ff\n",
    "    qkvo_proj = 4 * cfg.d_model * cfg.d_model\n",
    "    lm_head = cfg.vocab_size * cfg.d_model\n",
    "\n",
    "    total = token_embeddings + cfg.num_layers * (glu + qkvo_proj) + lm_head\n",
    "\n",
    "    return total\n",
    "\n",
    "\n",
    "def count_transformer_lm_activations(cfg: TransformerLMConfig) -> int:\n",
    "    layer_rms_norm = cfg.context_length * cfg.d_model\n",
    "\n",
    "    attn_kqv = cfg.context_length * 3 * cfg.d_model\n",
    "    attn_qk = cfg.context_length * cfg.context_length\n",
    "    attn_softmax = attn_qk\n",
    "    attn_values_weighted_sum = cfg.context_length * cfg.d_model\n",
    "    attn_output_projection = cfg.context_length * cfg.d_model\n",
    "    attn = attn_kqv + attn_qk + attn_softmax + attn_values_weighted_sum + attn_output_projection\n",
    "\n",
    "    ffn_w1_mm = cfg.context_length * cfg.d_ff\n",
    "    ffn_silu = ffn_w1_mm\n",
    "    ffn_w2_mm = ffn_w1_mm\n",
    "    ffn = ffn_w1_mm + ffn_silu + ffn_w2_mm\n",
    "\n",
    "    layer = 2 * layer_rms_norm + attn + ffn\n",
    "\n",
    "    final_rms_norm = cfg.context_length * cfg.d_model\n",
    "\n",
    "    output_embedding = cfg.context_length * cfg.vocab_size  # (logits)\n",
    "\n",
    "    total = cfg.num_layers * layer + final_rms_norm + output_embedding\n",
    "\n",
    "    return total\n",
    "\n",
    "\n",
    "def count_lm_transformer_adamw_memory_usage(cfg: TransformerLMConfig) -> int:\n",
    "    params = count_transformer_lm_params(cfg)\n",
    "    activations = count_transformer_lm_activations(cfg)\n",
    "\n",
    "    return params + activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
